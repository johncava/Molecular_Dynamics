# Hamiltonian Neural Networks | 2019
# Sam Greydanus, Misko Dzamba, Jason Yosinski
# Modified by Nick

import torch, argparse
import numpy as np
import pandas as pd
import time


import os, sys
THIS_DIR = os.path.dirname(os.path.abspath(""))
THIS_DIR = os.path.join(THIS_DIR, "Mol-HNN-cuda-v1")
# PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# sys.path.append(PARENT_DIR)

from cuda_nn_models import MLP
from cuda_hnn import HNN
from cuda_utils import L2_loss, to_pickle, from_pickle

from get_data import get_dataset, elapsed

import glob


PATH = "white-MOLHNNv1.pt"
outName = "HNNv2.xyz"
pred_steps = 1000
step_size = 0.005
noise_step = 0.1



# arrange data
def get_args():
    return {'input_dim': 240, # 40 atoms, each with q_x, q_y, p_z, p_y
         'hidden_dim': 200,
         'learn_rate': 1e-3,
         'input_noise': 0.1, ## NO INPUT NOISE YET
         'batch_size': 100,
         'nonlinearity': 'leaky',
#          'total_steps': total_steps, ## 3 epochs effectively i guess
         'field_type': 'solenoidal', ## change this? solenoidal
         'print_every': 200,
         'verbose': True,
         'name': '2body',
         'baseline' : False,
         'seed': 0,
         'save_dir': '{}'.format(THIS_DIR),
         'fig_dir': './figures'}


class ObjectView(object):
    def __init__(self, d): self.__dict__ = d

args = ObjectView(get_args())


#### THIS IS WHERE YOU INTERCEPT IF YOU WANT TO USE A DIFFERENT MODEL
output_dim = 2
nn_model = MLP(args.input_dim, args.hidden_dim, output_dim, args.nonlinearity)
model = HNN(args.input_dim, differentiable_model=nn_model,
        field_type=args.field_type, baseline=args.baseline)
optim = torch.optim.Adam(model.parameters(), args.learn_rate, weight_decay=0)


model.load_state_dict(torch.load(PATH))




######## LOADING THE DATA
if os.path.isfile(saved_x_dataset) and os.path.isfile(saved_dx_dataset):
    print("Found data files => loaded in the old data at:", saved_x_dataset)
    x_dataset = np.load(saved_x_dataset)
    dx_dataset = np.load(saved_dx_dataset)
    
else:
    print("Can't find data files => Creating a new set")
    x_dataset, dx_dataset = get_dataset(raw_data, saved_x_dataset, saved_dx_dataset, num_trajectories, num_atoms)

x = torch.tensor(x_dataset, requires_grad=True, dtype=torch.float32).cuda()
dxdt = torch.Tensor(dx_dataset).cuda()

# epoch_steps = int(x_dataset.shape[0] / batch_size)
# total_steps = int(epoch_steps * epochs)




### Autoregressive
initial_frame = x[0]
a = initial_frame
frames = []

for i in range(pred_steps):
    dx_hat = model.time_derivative(a.reshape(-1, 240))
    a = a + dx_hat * step_size
    a = a + torch.randn(a.shape).cuda() * noise_step # add noise, maybe
    
    new_frame = a.cpu().detach().numpy()
    new_frame = new_frame[:, :120].reshape(40, 3) ## converts the frame of coordinates into XYZ
    frames.append(new_frame)

frames = np.array(frames)



# Save predictions into VMD format
predictions = frames
frame_num = predictions.shape[0]

nAtoms = "40"
with open(outName, "w") as outputfile:
    for frame_idx in range(frame_num):
        
        frame = predictions[frame_idx]
        outputfile.write(str(nAtoms) + "\n")
        outputfile.write(" generated by JK\n")

        atomType = "CA"
        for i in range(40):
            line = str(frame[i][0]) + " " + str(frame[i][1]) + " " + str(frame[i][2]) + " "
            line += "\n"
            outputfile.write("  " + atomType + "\t" + line)

print("=> Finished Generation <=")